{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LR_Models.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa-86bOc8iA-"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib import collections  as mc\r\n",
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "import pandas as pd \r\n",
        "import seaborn as sns\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
        "sns.set_style(\"white\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPfjdYrEZ9pA"
      },
      "source": [
        "# Loading "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4G4puq9Z9pB"
      },
      "source": [
        "Below is how the dataset looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Y2ArCyy7Z9pC"
      },
      "source": [
        "\n",
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/project/training_data.csv\")\n",
        "df_test=pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/project/test_data.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9oPLwHJZ9pi"
      },
      "source": [
        "# I. Initial Classification Model: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFUY-ViuZ9pi"
      },
      "source": [
        "Our initial assumption is that the bydefault predictors (keyword, location and especially text) have a correlation or perhaps a causality with the fact that a tweet is either real or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwA29_fhZ9pk"
      },
      "source": [
        "## I.1. Raw Model: With Neither Dataframe Cleaning Nor Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0cg8R_urqIi"
      },
      "source": [
        "At this section, we are training the model on raw data, that means we are not cleaning them at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZGQ9L0ZZ9pk"
      },
      "source": [
        "### I.1.1. With One Predictor 'text'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWeBAZXlZ9pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "e8c00f93-81ff-4891-dc3f-99cb358ac797"
      },
      "source": [
        "# Select features\n",
        "X_train = df_train_copy['text'].values # the features we want to analyze\n",
        "y_train = df_train_copy['target'].values # the labels, or answers, we want to test against\n",
        "\n",
        "\n",
        "X_test = df_test['text'].values # the features we want to analyze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b09b4d5c32b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# the features we want to analyze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# the labels, or answers, we want to test against\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train_copy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0c2_5O1Z9pl"
      },
      "source": [
        "As per our intuition, we want to do this because TF-IDF takes of care unimportant words like most the stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4EfBa2WZ9pl"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf = True, max_df = 0.95)\n",
        "tfidf_vectorizer.fit_transform(X_train)\n",
        "        \n",
        "train_feature_set = tfidf_vectorizer.transform(X_train)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "O-sfiFBWZ9pl"
      },
      "source": [
        "classifier = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([('vectorizer', tfidf_vectorizer),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynKDIQ7yZ9pm"
      },
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EE5a6RlZ9pm"
      },
      "source": [
        "print(f\"ACCURACY SCORE:\\n{pipe.score(X_train, y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tonyNmMEZ9pn"
      },
      "source": [
        "This model gives a good train accuracy with not sanitized. Which already outperfoms the base rate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7QYBR5HZ9pn"
      },
      "source": [
        "### I.1.2 With Two predictors 'text' and 'keyword'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqDlI_hIrd-h"
      },
      "source": [
        "Merging Text and Keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLoWMd7OZ9po"
      },
      "source": [
        "df_train_copy['Text With Keyword'] = df_train_copy['keyword'].str.cat(df_train_copy['text'], sep =\" \") \n",
        "df_train_copy.drop(['text','keyword'],inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_3C17czZ9po"
      },
      "source": [
        "df_train_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K895yfuWZ9po"
      },
      "source": [
        "X_train_prdc_2 = df_train_copy['Text With Keyword'].values # the features we want to analyze\n",
        "\n",
        "X_train_prdc_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlw6rdsSZ9pp"
      },
      "source": [
        "tfidf_vectorizer_prd_2 = TfidfVectorizer(use_idf = True, max_df = 0.95)\n",
        "tfidf_vectorizer_prd_2.fit_transform(X_train_prdc_2.astype('U'))\n",
        "\n",
        "# x = v.fit_transform(df['Review'].values.astype('U'))  ## Even astype(str) would work\n",
        "\n",
        "tfidf_vectorizer_prd_2.transform(X_train_prdc_2.astype('U'))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghDCGcCZZ9pp"
      },
      "source": [
        "classifier_pred2 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "pipe_prd_2 = Pipeline([('vectorizer', tfidf_vectorizer_prd_2),\n",
        "                 ('classifier', classifier_pred2)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_prd_2.fit(X_train_prdc_2.astype('U'), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fAR1WYtZ9pq"
      },
      "source": [
        "y_pred_2p = pipe_prd_2.predict(X_test)\n",
        "y_pred_2p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyPXpDWsZ9pq"
      },
      "source": [
        "print(f\"ACCURACY SCORE:\\n{pipe_prd_2.score(X_train_prdc_2.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOeipyFOZ9pr"
      },
      "source": [
        "### I.1.3 With Two predictors 'text' and 'location'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A20rn9oBZ9ps"
      },
      "source": [
        "df_train_copy_6['Text With location'] = df_train_copy_6['location'].str.cat(df_train_copy_6['text'], sep =\" \") \n",
        "df_train_copy_6.drop(['text','location'],inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOepRmOcZ9ps"
      },
      "source": [
        "X_train_cl_p2_loc = df_train_copy_6['Text With location'].values\n",
        "\n",
        "X_train_cl_p2_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fTo6rXNZ9ps"
      },
      "source": [
        "tfidf_vectorizer_prd_2_loc = TfidfVectorizer(use_idf = True, max_df = 0.95)\n",
        "tfidf_vectorizer_prd_2_loc.fit_transform(X_train_cl_p2_loc.astype('U'))\n",
        "\n",
        "tfidf_vectorizer_prd_2_loc.transform(X_train_cl_p2_loc.astype('U'))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6N7y32CZ9pt"
      },
      "source": [
        "classifier_pred2_loc = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "pipe_prd_2_loc = Pipeline([('vectorizer', tfidf_vectorizer_prd_2_loc),\n",
        "                 ('classifier', classifier_pred2_loc)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_prd_2_loc.fit(X_train_cl_p2_loc.astype('U'), Y_train_cl_p2_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WYpgKEmZ9pt"
      },
      "source": [
        "y_pred_2p_loc = pipe_prd_2_loc.predict(X_test)\n",
        "y_pred_2p_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EVqvW1jZ9pu"
      },
      "source": [
        "print(f\"ACCURACY SCORE:\\n{pipe_prd_2_loc.score(X_train_cl_p2_loc.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj7UgquWZ9pv"
      },
      "source": [
        "### I.1.4 With Three predictors 'text', 'location' and 'keyword'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO5dCGA6Z9pv"
      },
      "source": [
        "df_train_copy['Text With Keyword and Location'] = df_train_copy['location'].str.cat(df_train_copy['Text With Keyword'], sep =\" \") \n",
        "df_train_copy.drop(['location','Text With Keyword'],inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvzOZXzVZ9pv"
      },
      "source": [
        "df_train_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx9x3SH5Z9pw"
      },
      "source": [
        "X_train_prdc_3 = df_train_copy['Text With Keyword and Location'].values # the features we want to analyze\n",
        "\n",
        "X_train_prdc_3#.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1PYim-KZ9pw"
      },
      "source": [
        "df_train_copy.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT7YyQcUZ9px"
      },
      "source": [
        "tfidf_vectorizer_prd_3 = TfidfVectorizer(use_idf = True, max_df = 0.95)\n",
        "tfidf_vectorizer_prd_3.fit_transform(X_train_prdc_3.astype('U'))\n",
        "\n",
        "tfidf_vectorizer_prd_3.transform(X_train_prdc_3.astype('U'))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtWAbfRSZ9px"
      },
      "source": [
        "classifier_pred3 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "\n",
        "# Create pipeline\n",
        "pipe_prd_3 = Pipeline([('vectorizer', tfidf_vectorizer_prd_3),\n",
        "                 ('classifier', classifier_pred3)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_prd_3.fit(X_train_prdc_3.astype('U'), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4li7-qEZ9py"
      },
      "source": [
        "y_pred_3p = pipe_prd_3.predict(X_test)\n",
        "y_pred_3p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBm458ZcZ9py"
      },
      "source": [
        "print(f\"ACCURACY SCORE:\\n{pipe_prd_3.score(X_train_prdc_2.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y5BuTR8Z9pz"
      },
      "source": [
        "## 2. Model With Text Cleaning but without DataFrame Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMs6r54BZ9p0"
      },
      "source": [
        "### 2.1. With a single Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4c5j4JbZ9p1"
      },
      "source": [
        "#### TF-IDF feature vectors\n",
        "\n",
        "create the TF-IDF feature vectors for the processed tweets. These will construct you data features that you will use to train a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xDMr24DZ9p1"
      },
      "source": [
        "tfidf_vector_1 = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrjX0kcpZ9p2"
      },
      "source": [
        "# Define classifier\n",
        "classifier_1 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_2 = Pipeline([('vectorizer', tfidf_vector_1),\n",
        "                 ('classifier', classifier_1)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_2.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKHW-JNDZ9p2"
      },
      "source": [
        "y_pred = pipe_2.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eavUWkITZ9p6"
      },
      "source": [
        "#### Accuracy\n",
        "\n",
        "- What is the test accuracy of the classifier?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nkfjlnrXZ9p7"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_2.score(X_train, y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtTEnQnXZ9p7"
      },
      "source": [
        "We observe that the accuracy has improved after pre-processing.\n",
        "#### Thus, we'll clean the data and redo the Model training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbsEdA7AZ9p8"
      },
      "source": [
        "### 2.2. With two Predictors: Keyword and Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VCD5bsXZ9p8"
      },
      "source": [
        "# Define classifier\n",
        "classifier_1 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_2 = Pipeline([('vectorizer', tfidf_vector_1),\n",
        "                 ('classifier', classifier_1)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_2.fit(X_train_prdc_2.astype('U'), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD5j128mZ9p_"
      },
      "source": [
        "y_pred_p_p2 = pipe_2.predict(X_test)\n",
        "y_pred_p_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "989TldqTZ9qA"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_2.score(X_train_prdc_2.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EpKWguWZ9qB"
      },
      "source": [
        "### 2.3. With two Predictors: Location and Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTxBPK4eZ9qB"
      },
      "source": [
        "# Define classifier\n",
        "classifier_1 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_2 = Pipeline([('vectorizer', tfidf_vector_1),\n",
        "                 ('classifier', classifier_1)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_2.fit(X_train_cl_p2_loc.astype('U'), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37uliXdIZ9qB"
      },
      "source": [
        "y_pred_p_p2 = pipe_2.predict(X_test)\n",
        "y_pred_p_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D72mDjiZ9qC"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_2.score(X_train_cl_p2_loc.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMrRrxYwZ9qD"
      },
      "source": [
        "### 2.4. With All Predictors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDUKV8OZZ9qD"
      },
      "source": [
        "# Define classifier\n",
        "classifier_1 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_2 = Pipeline([('vectorizer', tfidf_vector_1),\n",
        "                 ('classifier', classifier_1)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_2.fit(X_train_prdc_3.astype('U'), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx0M3OC8Z9qD"
      },
      "source": [
        "y_pred_p_p3 = pipe_2.predict(X_test)\n",
        "y_pred_p_p3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4iJ3mXdZ9qE"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_2.score(X_train_prdc_3.astype('U'), y_train):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPQBIcD5Z9qW"
      },
      "source": [
        "## 3. Model With Text Cleaning Anf DataFrame Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-xyq0ycvYaO"
      },
      "source": [
        "Here, we do cleaning related to the dataframe as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riVO0bKWZ9qW"
      },
      "source": [
        "### 3.1. Non Balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eQndmQxv82-"
      },
      "source": [
        "The below models are of our dataset as-is without rebalancing it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyTte765Z9qX"
      },
      "source": [
        "#### Single Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ9ueqlsZ9qX"
      },
      "source": [
        "# Select features\n",
        "X_train_cl_1 = df_train_clean_copy['text'].values # the features we want to analyze\n",
        "Y_train_cl_1 = df_train_clean_copy['target'].values\n",
        "X_train_cl_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgJrMKfyZ9qX"
      },
      "source": [
        "Y_train_cl_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEBn--9GZ9qY"
      },
      "source": [
        "tfidf_vector_2 = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znJYYOMJZ9qZ"
      },
      "source": [
        "# Define classifier\n",
        "classifier_2 = LogisticRegression(solver='saga', max_iter=1000, random_state = 72)\n",
        "\n",
        "# Create pipeline\n",
        "pipe_3 = Pipeline([('vectorizer', tfidf_vector_2),\n",
        "                 ('classifier', classifier_2)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_cl_1, Y_train_cl_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL_q22lqZ9qZ"
      },
      "source": [
        "y_pred_3 = pipe_3.predict(X_test)\n",
        "y_pred_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd_vZV2_Z9qZ"
      },
      "source": [
        " Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIKCIthTZ9qa"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_cl_1, Y_train_cl_1):.6f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ZAYVnXZ9qa"
      },
      "source": [
        "There is a sligth improvement after cleaning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fp_2EVZ9qa"
      },
      "source": [
        "#### Two Predictors: Text and Keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwWXKmSZ9qb"
      },
      "source": [
        "X_train_cl_p2 = df_train_copy_1['Text With Keyword'].values\n",
        "Y_train_cl_p2 = df_train_copy_1['target'].values\n",
        "X_train_cl_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDtczNw_Z9qb"
      },
      "source": [
        "Y_train_cl_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbF6sbzaZ9qb"
      },
      "source": [
        "# Define classifier\n",
        "\n",
        "pipe_3.fit(X_train_cl_p2, Y_train_cl_p2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW01Nei6Z9qc"
      },
      "source": [
        "y_pred_3 = pipe_3.predict(X_test)\n",
        "y_pred_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_H9N1lUZ9qc"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_2.score(X_train_cl_p2, Y_train_cl_p2):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSLvNmlZ9ql"
      },
      "source": [
        "#### Two Predictors: Text and location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjDRa_IGZ9qm"
      },
      "source": [
        "df_train_copy_3.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LQR_GfuZ9qm"
      },
      "source": [
        "X_train_cl_p2_loc = df_train_copy_3['Text With location'].values\n",
        "Y_train_cl_p2_loc = df_train_copy_3['target'].values\n",
        "X_train_cl_p2_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rkfi627Z9qm"
      },
      "source": [
        "\n",
        "pipe_3.fit(X_train_cl_p2_loc, Y_train_cl_p2_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4alJ_0WZ9qn"
      },
      "source": [
        "y_pred_3 = pipe_3.predict(X_test)\n",
        "y_pred_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nMkD9dZ9qn"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_cl_p2_loc, Y_train_cl_p2_loc):.6f}\") #hv a look"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY4lTmFQZ9qo"
      },
      "source": [
        "##### Three Predictors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzhKUPU1Z9qo"
      },
      "source": [
        "X_train_cl_p3_loc = df_train_copy_2['Text With Keyword and Location'].values\n",
        "Y_train_cl_p3_loc = df_train_copy_2['target'].values\n",
        "X_train_cl_p3_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEt891k1Z9qo"
      },
      "source": [
        "Y_train_cl_p3_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNabUe6JZ9qp"
      },
      "source": [
        "# Define classifier\n",
        "\n",
        "pipe_3.fit(X_train_cl_p3_loc, Y_train_cl_p3_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29T-2yCIZ9qp"
      },
      "source": [
        "y_pred_cl_3 = pipe_3.predict(X_test)\n",
        "y_pred_cl_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNhsEXVGZ9qq"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_cl_p3_loc, Y_train_cl_p3_loc):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmyb0DNvZ9qq"
      },
      "source": [
        "### 3.2. ReBalanced Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f21_0Jw5xXuC"
      },
      "source": [
        "In the below models, we rebalanced the dataframe. And we have done both a downgrade and a broadening one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQ2L35ZZ9qr"
      },
      "source": [
        "##### Balancing about text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "76XhgAQ7Z9qr"
      },
      "source": [
        "# Create balanced dataframe - base rate = 0.5 around text #single predictor\n",
        "df_new_blc = pd.concat([df_train_clean_copy[df_train_clean_copy[\"target\"] == 0].sample(len(df_train_clean_copy[df_train_clean_copy[\"target\"] == 1])), df_train_clean_copy[df_train_clean_copy[\"target\"] == 1]], axis=0).reset_index()\n",
        "df_new_blc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdypgGo7Z9qs"
      },
      "source": [
        "len(df_new_blc[df_new_blc['target']==0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079ZhvC1Z9qs"
      },
      "source": [
        "##### Single Predictor balanced "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRQjYLi2Z9qs"
      },
      "source": [
        "X_train_blcd_p1 = df_new_blc['text'].values\n",
        "Y_train_blcd_p1 = df_new_blc['target'].values\n",
        "X_train_blcd_p1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn1eAE-aZ9q4"
      },
      "source": [
        "Y_train_blcd_p1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ch4HWF1Z9q5"
      },
      "source": [
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_blcd_p1, Y_train_blcd_p1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwDCjCWwZ9q5"
      },
      "source": [
        "y_pred_blcd = pipe_3.predict(X_test)\n",
        "y_pred_blcd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rLKQYeHZ9q5"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_blcd_p1, Y_train_blcd_p1):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GwpnrZeZ9q6"
      },
      "source": [
        "##### Two Predictors : Text and keyword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqL2yFnHoCHk"
      },
      "source": [
        "**we need a clean df with these two params**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx1w0naoZ9q7"
      },
      "source": [
        "# Create balanced dataframe - base rate = 0.5 around text #single predictor\n",
        "df_new_blc_2pdt = pd.concat([df_train_copy_1[df_train_copy_1[\"target\"] == 0].sample(len(df_train_copy_1[df_train_copy_1[\"target\"] == 1])), df_train_copy_1[df_train_copy_1[\"target\"] == 1]], axis=0).reset_index()\n",
        "df_new_blc_2pdt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BYFdJ3KZ9q7"
      },
      "source": [
        "X_train_blcd_p2 = df_new_blc_2pdt['Text With Keyword'].values\n",
        "Y_train_blcd_p2 = df_new_blc_2pdt['target'].values\n",
        "X_train_blcd_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L9XuLKBZ9q7"
      },
      "source": [
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_blcd_p2, Y_train_blcd_p2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a2oiYnlZ9q8"
      },
      "source": [
        "y_pred_blc_p2 = pipe_3.predict(X_test)\n",
        "y_pred_blc_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj0bv6qGZ9q8"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_blcd_p2, Y_train_blcd_p2):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78N5l_JZ9q9"
      },
      "source": [
        "##### Two Predictors : Text and location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53BD1NX5Z9q9"
      },
      "source": [
        "# Create balanced dataframe - base rate = 0.5 around text #single predictor\n",
        "df_new_blc_2pd_loc = pd.concat([df_train_copy_3[df_train_copy_3[\"target\"] == 0].sample(len(df_train_copy_3[df_train_copy_3[\"target\"] == 1])), df_train_copy_3[df_train_copy_3[\"target\"] == 1]], axis=0).reset_index()\n",
        "df_new_blc_2pd_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCYFeYCnZ9q-"
      },
      "source": [
        "X_train_blcd_p2_loc = df_new_blc_2pd_loc['Text With location'].values\n",
        "Y_train_blcd_p2_loc = df_new_blc_2pd_loc['target'].values\n",
        "X_train_blcd_p2_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8hSiYc6oNL0"
      },
      "source": [
        "Fit model on training set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPDj4GazZ9q-"
      },
      "source": [
        "\n",
        "pipe_3.fit(X_train_blcd_p2_loc, Y_train_blcd_p2_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHxi0JKyZ9q-"
      },
      "source": [
        "y_pred_blc_p2_loc = pipe_3.predict(X_test)\n",
        "y_pred_blc_p2_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7VLUfhZ9q_"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_blcd_p2_loc, Y_train_blcd_p2_loc):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulHFsSAZ9rA"
      },
      "source": [
        "##### Three Predictors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nheqNC5hoWKL"
      },
      "source": [
        "Create balanced dataframe - base rate = 0.5 around text #single predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fVOCGFnZ9rA"
      },
      "source": [
        "\n",
        "df_new_blc_3pd = pd.concat([df_train_copy_2[df_train_copy_2[\"target\"] == 0].sample(len(df_train_copy_2[df_train_copy_2[\"target\"] == 1])), df_train_copy_2[df_train_copy_2[\"target\"] == 1]], axis=0).reset_index()\n",
        "df_new_blc_3pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK9mRs4QZ9rA"
      },
      "source": [
        "X_train_blcd_p3 = df_new_blc_3pd['Text With Keyword and Location'].values\n",
        "Y_train_blcd_p3 = df_new_blc_3pd['target'].values\n",
        "X_train_blcd_p3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odXBHKm5Z9rB"
      },
      "source": [
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_blcd_p3, Y_train_blcd_p3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W9RTTb1Z9rB"
      },
      "source": [
        "y_pred_blc_p3 = pipe_3.predict(X_test)\n",
        "y_pred_blc_p3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Qd2vlPZ9rB"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_blcd_p3, Y_train_blcd_p3):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsCSvd_LZ9rC"
      },
      "source": [
        "## broadening "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0COyrNWZ9rC"
      },
      "source": [
        "from sklearn.utils import resample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl3_f-U4Z9rD"
      },
      "source": [
        "### Single Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJJVov6Z9rD"
      },
      "source": [
        "df_train_clean_copy[df_train_clean_copy['target'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3rvz2vJZ9rD"
      },
      "source": [
        "df_majority = df_train_clean_copy[df_train_clean_copy['target'] == 0]\n",
        "df_minority = df_train_clean_copy[df_train_clean_copy['target'] == 1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=3665,    # to match majority class\n",
        "                                 random_state=1234) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled.target.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvuyx-yBZ9rE"
      },
      "source": [
        "# Create balanced dataframe - base rate = 0.5 around text #single predictor\n",
        "df_upsampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GxweMOjZ9rE"
      },
      "source": [
        "X_train_blcd_p11 = df_upsampled['text'].values\n",
        "Y_train_blcd_p11 = df_upsampled['target'].values\n",
        "X_train_blcd_p11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2DuepbaZ9rF"
      },
      "source": [
        "Y_train_blcd_p11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXI3wlmjZ9rF"
      },
      "source": [
        "pipe_3.fit(X_train_blcd_p11, Y_train_blcd_p11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEBuXN2DZ9rF"
      },
      "source": [
        "y_pred_33 = pipe_3.predict(X_test)\n",
        "y_pred_33"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQufsBXDZ9rG"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_blcd_p11, Y_train_blcd_p11):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHXOW3baZ9rH"
      },
      "source": [
        "### Two Predictors: Keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEMha5E2Z9rH"
      },
      "source": [
        "df_train_copy_1[df_train_copy_1['target'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7VdgGkYZ9rH"
      },
      "source": [
        "df_majority_p2 = df_train_copy_1[df_train_copy_1['target'] == 0]\n",
        "df_minority_p2 = df_train_copy_1[df_train_copy_1['target'] == 1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled_1 = resample(df_minority_p2, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=3665,    # to match majority class\n",
        "                                 random_state=1234) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled_1 = pd.concat([df_majority_p2, df_minority_upsampled_1])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled_1.target.value_counts()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OR-uBQCZ9rI"
      },
      "source": [
        "X_train_upblcd_p2 = df_upsampled_1['Text With Keyword'].values\n",
        "Y_train_upblcd_p2 = df_upsampled_1['target'].values\n",
        "X_train_upblcd_p2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4cP4CyqZ9rJ"
      },
      "source": [
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_upblcd_p2, Y_train_upblcd_p2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k__1U4fmZ9rL"
      },
      "source": [
        "y_pred_up_blc = pipe_3.predict(X_test)\n",
        "y_pred_up_blc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEs5DAnQZ9rM"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_upblcd_p2, Y_train_upblcd_p2):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HrGi05ZZ9rN"
      },
      "source": [
        "### Two Predictors: location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVgVj1c7Z9rN"
      },
      "source": [
        "df_train_copy_3[df_train_copy_3['target'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lwLCnKuZ9rO"
      },
      "source": [
        "df_majority_p2_loc = df_train_copy_3[df_train_copy_3['target'] == 0]\n",
        "df_minority_p2_loc = df_train_copy_3[df_train_copy_3['target'] == 1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled_2 = resample(df_minority_p2_loc, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=2464,    # to match majority class\n",
        "                                 random_state=1234) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled_2 = pd.concat([df_majority_p2_loc, df_minority_upsampled_2])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled_2.target.value_counts()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9JFnDbrZ9rO"
      },
      "source": [
        "X_train_upblcd_p2_loc = df_upsampled_2['Text With location'].values\n",
        "Y_train_upblcd_p2_loc = df_upsampled_2['target'].values\n",
        "X_train_upblcd_p2_loc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tci_pOnYZ9rP"
      },
      "source": [
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_upblcd_p2_loc, Y_train_upblcd_p2_loc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3xWSoHQZ9rP"
      },
      "source": [
        "y_pred_up_blc = pipe_3.predict(X_test)\n",
        "y_pred_up_blc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw8vGV4KZ9rQ"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_upblcd_p2_loc, Y_train_upblcd_p2_loc):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZKR8l08Z9rQ"
      },
      "source": [
        "### Three Predictors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKxEDV2IZ9rQ"
      },
      "source": [
        "df_train_copy_2[df_train_copy_2['target'] == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P1HA52KZ9rR"
      },
      "source": [
        "df_majority_p3 = df_train_copy_2[df_train_copy_2['target'] == 0]\n",
        "df_minority_p3 = df_train_copy_2[df_train_copy_2['target'] == 1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled_3 = resample(df_minority_p3, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=2464,    # to match majority class\n",
        "                                 random_state=1234) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled_3 = pd.concat([df_majority_p3, df_minority_upsampled_3])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled_3.target.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELKzjgeBZ9rS"
      },
      "source": [
        "X_train_upblcd_p3 = df_upsampled_3['Text With Keyword and Location'].values\n",
        "Y_train_upblcd_p3 = df_upsampled_3['target'].values\n",
        "X_train_upblcd_p3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS0Rx7ElZ9rS"
      },
      "source": [
        "\n",
        "# Fit model on training set\n",
        "pipe_3.fit(X_train_upblcd_p3, Y_train_upblcd_p3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MiJMLkoZ9rT"
      },
      "source": [
        "y_pred_up3_blc = pipe_3.predict(X_test)\n",
        "y_pred_up3_blc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IghToSSBZ9rT"
      },
      "source": [
        "# Evaluate on training set\n",
        "print(f\"ACCURACY SCORE:\\n{pipe_3.score(X_train_upblcd_p3, Y_train_upblcd_p3):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}